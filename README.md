# ğŸ˜ƒ Facial Emotion Recognition using CNN

A deep learning-based facial emotion classifier that can detect **7 emotions** from facial images. This project is built using **Keras**, **TensorFlow**, **OpenCV**, and is trained on the **FER2013** dataset.

---

## ğŸš€ Features

- ğŸ§  Trained CNN with 4 convolutional layers
- ğŸ§ª Tested on FER2013 test set
- ğŸ¯ Recognizes 7 emotions: Angry, Disgust, Fear, Happy, Neutral, Sad, Surprise
- ğŸ¥ Real-time webcam emotion prediction
- ğŸ’¾ Pre-trained model weights available

---

## ğŸ› ï¸ Tech Stack

- **Language**: Python  
- **Libraries**: TensorFlow, Keras, NumPy, Pandas, OpenCV, tqdm  
- **Tools**: Jupyter Notebook, OpenCV Webcam, Google Drive (for model storage)

---

---

## ğŸ§  Model Overview

- âœ… **4 Convolutional Layers** with ReLU activation  
- âœ… **MaxPooling + Dropout** after each conv layer  
- âœ… **2 Dense (Fully Connected) Layers**  
- âœ… **Output Layer** with 7 neurons and Softmax activation  
- âœ… Trained with Categorical Crossentropy & Adam Optimizer  

---

## ğŸ”— Resources

- ğŸ“¦ Dataset: [FER2013 on Kaggle](https://www.kaggle.com/datasets/jonathanoheix/face-expression-recognition-dataset)  
- ğŸ“¥ Trained Model Files: [Google Drive](https://drive.google.com/drive/folders/1-SCxdgtrnEaK2iX6_YX0mIO0siRGS2WN?usp=drive_link)

---

## ğŸ’» Setup & Installation

1. **Clone the Repository**
```bash
git clone https://github.com/yourusername/emotion-recognition.git
cd emotion-recognition
```
## ğŸ’» Setup & Installation

### 2. Create a Virtual Environment (Optional)
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```
### 3. Install Requirements
Install all required Python libraries using the command below:

```bash
pip install -r requirements.txt
```

### 4. Download Trained Model
Download the pre-trained model files from [Google Drive](https://drive.google.com/drive/folders/1-SCxdgtrnEaK2iX6_YX0mIO0siRGS2WN?usp=drive_link) and place them in the root directory of your project:
- `facialemotionmodel.json` â€” Model architecture
- `facialemotionmodel.h5` â€” Model weights

### 5. Run the Notebook
To train or test the model, open the Jupyter notebook:

```bash
jupyter notebook modeltrain.ipynb


